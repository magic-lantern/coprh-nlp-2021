{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8fe1817",
   "metadata": {},
   "source": [
    "# Example of how to use Deep Learning for text classification\n",
    "\n",
    "Click [Text Classification Example](https://colab.research.google.com/github/magic-lantern/coprh-nlp-2021/blob/main/text_classification_colab.ipynb) to open this notebook in Google Colab - no local setup required, results saved to your Google Drive.\n",
    "\n",
    "In Google Colab, make sure you change the Runtime to a GPU instance - that will result vastly improved runtimes for deep learning steps. On CPU based hardware some steps take 40 minutes versus 1 minute per training epoch on systems with a GPU. Steps to update runtime:\n",
    "\n",
    "    Runtime > Change runtime type > Select 'GPU' in Hardware accelerator box\n",
    "\n",
    "Click 'Save' to switch from Default runtime to GPU accelerated runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477f2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('this is a new python cell')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefff91a",
   "metadata": {},
   "source": [
    "this is a new markdown cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell makes sure Google Colab version has latest software dependencies\n",
    "!pip install -Uqq fastbook fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec45b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastbook\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd58e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell will setup a path that allows you to load and save files to your google drive\n",
    "# you will be prompted to log in with a Google enabled account.\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe22952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27edf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = fastbook.gdrive / Path('data')\n",
    "data_file = data_path / 'mtsamples.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fadf0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b3c102",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_file.is_file():\n",
    "    print('Already downloaded')\n",
    "else:\n",
    "    print('downloading data file')\n",
    "    download_data(\n",
    "        url='https://github.com/socd06/medical-nlp/raw/master/data/mtsamples.csv',\n",
    "        fname = data_file\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4af966",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtsamples = pd.read_csv(str(data_path) + '/mtsamples.csv')\n",
    "mtsamples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ff205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find rows where number of words is very low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ca1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_len = mtsamples.transcription.str.split(' ').str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtsamples['num_words'] =  mtsamples.transcription.str.split(' ').str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_len.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd7336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_len.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1afc98",
   "metadata": {},
   "source": [
    "A note on data cleanup. In the best case, a machine learning model can only be as good as the data provided. If data is of poor quality or inconsistent, it will be difficult to get good accuracy with your model.\n",
    "\n",
    "Let's review the really short transcription notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d1bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(mtsamples[mtsamples['num_words'] < 5])} records with short notes.\")\n",
    "mtsamples[mtsamples['num_words'] < 5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8cd7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop transcripts with fewer than 5 words - they are not good notes\n",
    "mtsamples = mtsamples[mtsamples['num_words'] >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtsamples.medical_specialty.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fb6dc2",
   "metadata": {},
   "source": [
    "This is one way to load the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72774f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "TextDataLoaders.from_df(mtsamples,\n",
    "                        valid_pct=0.2,\n",
    "                        seed=42,\n",
    "                        text_col='transcription',\n",
    "                        label_col='medical_specialty',\n",
    "                        seq_len=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12149318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls_lm = DataBlock(\n",
    "#     blocks=(TextBlock.from_df('transcription', is_lm=True), CategoryBlock),\n",
    "#     get_x=ColReader('transcription'), \n",
    "#     get_y=ColReader('medical_specialty'),\n",
    "#     splitter=TrainTestSplitter(test_size=0.2,\n",
    "#                                random_state=42,\n",
    "#                                stratify=mtsamples.medical_specialty)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a65e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_lm = DataBlock(\n",
    "    blocks=TextBlock.from_df('transcription', is_lm=True),\n",
    "    get_x=ColReader('text'),\n",
    "    splitter=TrainTestSplitter(test_size=0.2,\n",
    "                               random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3337c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if changes in the above were made (such as batch size), it may be beneficial to purge GPU memory\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc358b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes 1 - 2 minutes\n",
    "# when using seq_len, bs of 128 fits in GPU memory, bs 256 does not fit\n",
    "dls_lm = dls_lm.dataloaders(mtsamples, bs=128, seq_len=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49354b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_lm.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d642f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_learn = language_model_learner(\n",
    "    dls_lm,\n",
    "    AWD_LSTM,\n",
    "    model_dir=fastbook.gdrive / Path('data'),\n",
    "    drop_mult=0.3,\n",
    "    metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915814fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on macbook this takes 40 minues\n",
    "# on GPU machine this takes about 1 minute\n",
    "lm_learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60d5389",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_learn.save('1stepoch')\n",
    "# can load already saved trained model with\n",
    "# learn.load('1stepoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41db8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if changes in the above were made (such as batch size), it may be beneficial to purge GPU memory\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f857a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_learn.unfreeze()\n",
    "lm_learn.fit_one_cycle(10, 2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_learn.save_encoder('finetuned')\n",
    "# can load with\n",
    "# lm_learn.load('finetuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deab493b",
   "metadata": {},
   "source": [
    "## Now build a text classifier\n",
    "\n",
    "Now that we have finetuned a language model based on our actual text let's build a classifier to identify the medical specialty of the transcription notes. As shown previously in this dataset, some specialties are more represented than others. Split data such that training and testing data sets are balanced based on specialty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982bac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell takes about 2 minutes to run\n",
    "dls_clas = DataBlock(\n",
    "    blocks=(TextBlock.from_df('transcription', vocab=dls_lm.vocab), CategoryBlock),\n",
    "    get_x=ColReader('text'),\n",
    "    get_y=ColReader('medical_specialty'),\n",
    "    splitter=TrainTestSplitter(test_size=0.2,\n",
    "                               random_state=42,\n",
    "                               stratify=mtsamples.medical_specialty)\n",
    ").dataloaders(mtsamples, bs=128, seq_len=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62acb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_clas.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac12345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(\n",
    "    dls_clas,\n",
    "    AWD_LSTM,\n",
    "    drop_mult=0.5,\n",
    "    metrics=accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the encoder used for the language model - must be the same to build off language model.\n",
    "learn = learn.load_encoder('finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b92d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 2e-2)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.3",
    "jupytext_version": "1.11.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
