{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8fe1817",
   "metadata": {
    "id": "c8fe1817"
   },
   "source": [
    "# Example of how to use Deep Learning for text classification\n",
    "\n",
    "Click [Text Classification Example](https://colab.research.google.com/github/magic-lantern/coprh-nlp-2021/blob/main/text_classification_colab.ipynb) to open this notebook in Google Colab - no local setup required, results saved to your Google Drive.\n",
    "\n",
    "In Google Colab, make sure you change the Runtime to a GPU instance - that will result vastly improved runtimes for deep learning steps. On CPU based hardware some steps take 40 minutes versus 1 minute per training epoch on systems with a GPU. Steps to update runtime:\n",
    "\n",
    "    Runtime > Change runtime type > Select 'GPU' in Hardware accelerator box\n",
    "\n",
    "Click 'Save' to switch from Default runtime to GPU accelerated runtime.\n",
    "\n",
    "Some useful links:\n",
    "\n",
    "* https://muellerzr.github.io/fastblog/2020/08/21/intermediate.html#A-Text-Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc132e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99dc132e",
    "outputId": "c828b4e3-acba-4673-c15d-7d84b1b4a135"
   },
   "outputs": [],
   "source": [
    "# this cell makes sure Google Colab version has latest software dependencies\n",
    "!pip install -Uqq fastbook fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec45b4",
   "metadata": {
    "id": "b8ec45b4"
   },
   "outputs": [],
   "source": [
    "import fastbook\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd58e7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccd58e7d",
    "outputId": "89ac7515-7198-4822-f872-0103a4747168"
   },
   "outputs": [],
   "source": [
    "# this cell will setup a path that allows you to load and save files to your google drive\n",
    "# you will be prompted to log in with a Google enabled account.\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a1f20",
   "metadata": {
    "id": "be0a1f20"
   },
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe22952b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe22952b",
    "outputId": "79ce185f-29e1-4127-b175-c193b308a8b8"
   },
   "outputs": [],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27edf42",
   "metadata": {
    "id": "c27edf42"
   },
   "outputs": [],
   "source": [
    "data_path = fastbook.gdrive / Path('data')\n",
    "data_file = data_path / 'mtsamples.csv'\n",
    "sequence_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fadf0a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fadf0a4",
    "outputId": "318bd4bc-6be0-4efb-ff7a-881952b23805"
   },
   "outputs": [],
   "source": [
    "data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b3c102",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59b3c102",
    "outputId": "d6daf195-096c-43b8-eb74-1ffab24bdbaf"
   },
   "outputs": [],
   "source": [
    "if data_file.is_file():\n",
    "    print('Already downloaded')\n",
    "else:\n",
    "    print('downloading data file')\n",
    "    download_data(\n",
    "        url='https://github.com/socd06/medical-nlp/raw/master/data/mtsamples.csv',\n",
    "        fname = data_file\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4af966",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "8a4af966",
    "outputId": "7d84c1e2-192d-4d75-99f1-d1ff7704575e"
   },
   "outputs": [],
   "source": [
    "mtsamples = pd.read_csv(str(data_path) + '/mtsamples.csv')\n",
    "mtsamples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1afc98",
   "metadata": {
    "id": "7b1afc98"
   },
   "source": [
    "A note on data cleanup. In the best case, a machine learning model can only be as good as the data provided. If data is of poor quality or inconsistent, it will be difficult to get good accuracy with your model.\n",
    "\n",
    "Let's review the really short transcription notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ca1fd",
   "metadata": {
    "id": "9d6ca1fd"
   },
   "outputs": [],
   "source": [
    "word_len = mtsamples.transcription.str.split(' ').str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112b29d",
   "metadata": {
    "id": "b112b29d"
   },
   "outputs": [],
   "source": [
    "mtsamples['num_words'] =  mtsamples.transcription.str.split(' ').str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20489c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c20489c",
    "outputId": "7194b663-13c8-42a5-f55f-06bc800005bd"
   },
   "outputs": [],
   "source": [
    "word_len.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd7336a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffd7336a",
    "outputId": "8696e7cb-b42c-4067-83af-a9986276fbab"
   },
   "outputs": [],
   "source": [
    "word_len.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d1bc7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "826d1bc7",
    "outputId": "856f38df-c4b5-4e13-8878-5413a8b9f99a"
   },
   "outputs": [],
   "source": [
    "print(f\"There are {len(mtsamples[mtsamples['num_words'] < 5])} records with short notes.\")\n",
    "mtsamples[mtsamples['num_words'] < 5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8cd7fe",
   "metadata": {
    "id": "4c8cd7fe"
   },
   "outputs": [],
   "source": [
    "# drop transcripts with fewer than 5 words - they are not good notes\n",
    "mtsamples = mtsamples[mtsamples['num_words'] >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3103b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3d3103b",
    "outputId": "7956d665-c1fb-4e95-e8f4-abbaded0b725"
   },
   "outputs": [],
   "source": [
    "mtsamples.medical_specialty.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fb6dc2",
   "metadata": {
    "id": "24fb6dc2"
   },
   "source": [
    "This is one way to load the data for training - it's more simple, but you have less control.\n",
    "\n",
    "```python\n",
    "TextDataLoaders.from_df(mtsamples,\n",
    "                        valid_pct=0.2,\n",
    "                        seed=42,\n",
    "                        text_col='transcription',\n",
    "                        label_col='medical_specialty',\n",
    "                        seq_len=72)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a65e61",
   "metadata": {
    "id": "b4a65e61"
   },
   "outputs": [],
   "source": [
    "dls_lm = DataBlock(\n",
    "    blocks=TextBlock.from_df('transcription', is_lm=True),\n",
    "    get_x=ColReader('text'),\n",
    "    splitter=TrainTestSplitter(test_size=0.2,\n",
    "                               random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3337c6",
   "metadata": {
    "id": "9e3337c6"
   },
   "outputs": [],
   "source": [
    "# if changes in the above were made (such as batch size), it may be beneficial to purge GPU memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc358b72",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "fc358b72",
    "outputId": "8619ff6d-3886-48a2-82d3-6cfce32193b2"
   },
   "outputs": [],
   "source": [
    "# This cell takes 1 - 2 minutes\n",
    "# when using seq_len of 256, bs of 128 fits in GPU memory, bs 256 does not fit\n",
    "# when using seq_len of 512, bs of 64 fits in GPU memory, bs 128 does not fit\n",
    "dls_lm = dls_lm.dataloaders(mtsamples, bs=64, seq_len=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49354b58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "49354b58",
    "outputId": "a4cc377e-0e56-4d41-ca70-7effea4da5ec"
   },
   "outputs": [],
   "source": [
    "dls_lm.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d642f450",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "d642f450",
    "outputId": "0f382557-04cc-4de0-8d6d-34cfb3092425"
   },
   "outputs": [],
   "source": [
    "lm_learn = language_model_learner(\n",
    "    dls_lm,\n",
    "    AWD_LSTM,\n",
    "    model_dir=fastbook.gdrive / Path('data'),\n",
    "    drop_mult=0.3,\n",
    "    metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915814fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "915814fd",
    "outputId": "758d7862-419a-4db2-e2eb-5a593b63b06b"
   },
   "outputs": [],
   "source": [
    "# on macbook this cell takes 40 minues\n",
    "# on GPU machine this cell takes about 1 minute\n",
    "lm_learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60d5389",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a60d5389",
    "outputId": "116ea826-93f2-4ad0-cda0-9ebe40e38423"
   },
   "outputs": [],
   "source": [
    "lm_learn.save('1stepoch')\n",
    "# can load already saved trained model with\n",
    "# learn.load('1stepoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41db8bc",
   "metadata": {
    "id": "d41db8bc"
   },
   "outputs": [],
   "source": [
    "# if changes in the above were made (such as batch size), it may be beneficial to purge GPU memory\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f857a0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "6f857a0a",
    "outputId": "3c89f57b-cb53-48e4-ef45-08e609c0ec51"
   },
   "outputs": [],
   "source": [
    "lm_learn.unfreeze()\n",
    "lm_learn.fit_one_cycle(20, 2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe4759",
   "metadata": {
    "id": "eefe4759"
   },
   "outputs": [],
   "source": [
    "lm_learn.save_encoder('finetuned')\n",
    "# can load with\n",
    "# lm_learn.load('finetuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deab493b",
   "metadata": {
    "id": "deab493b"
   },
   "source": [
    "## Now build a text classifier\n",
    "\n",
    "Now that we have finetuned a language model based on our actual text let's build a classifier to identify the medical specialty of the transcription notes. As shown previously in this dataset, some specialties are more represented than others. Split data such that training and testing data sets are balanced based on specialty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982bac9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "982bac9a",
    "outputId": "95dc2352-8451-487a-b179-a5163d64e2a3"
   },
   "outputs": [],
   "source": [
    "# this cell takes about 2 minutes to run\n",
    "dls_clas = DataBlock(\n",
    "    blocks=(TextBlock.from_df('transcription', vocab=dls_lm.vocab), CategoryBlock),\n",
    "    get_x=ColReader('text'),\n",
    "    get_y=ColReader('medical_specialty'),\n",
    "    splitter=TrainTestSplitter(test_size=0.2,\n",
    "                               random_state=42,\n",
    "                               stratify=mtsamples.medical_specialty)\n",
    ").dataloaders(mtsamples, bs=128, seq_len=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62acb3b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "e62acb3b",
    "outputId": "b79264d6-d1bb-44b1-ff4c-5e146cc2ea01"
   },
   "outputs": [],
   "source": [
    "dls_clas.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac12345f",
   "metadata": {
    "id": "ac12345f"
   },
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(\n",
    "    dls_clas,\n",
    "    AWD_LSTM,\n",
    "    drop_mult=0.3,\n",
    "    metrics=accuracy,\n",
    "    model_dir=fastbook.gdrive / Path('data')).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a043a",
   "metadata": {
    "id": "8c2a043a"
   },
   "outputs": [],
   "source": [
    "# load the encoder used for the language model - must be the same to build off language model.\n",
    "learn = learn.load_encoder('finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eMmosjDCzBT2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "eMmosjDCzBT2",
    "outputId": "4f792eee-89a9-4931-ec35-d539678dd9ea"
   },
   "outputs": [],
   "source": [
    "# attempt to find a decent learning rate for this dataset\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b92d1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "e3b92d1a",
    "outputId": "eafd2cce-1918-46aa-d3ea-c98b294e057f"
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 3e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8mYtXu2nvhat",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "8mYtXu2nvhat",
    "outputId": "8039c17d-3676-4ae8-9347-6631ec133278"
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(1e-1/(2.6**4),1e-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prnKbBnZvnwr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "prnKbBnZvnwr",
    "outputId": "fcfb7c27-ea4c-4325-9b75-cbdb968a5b41"
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-2/(2.6**4),5e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l781vmBVvqbb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "l781vmBVvqbb",
    "outputId": "0a3f610f-b2fa-4107-e865-6e673fea041f"
   },
   "outputs": [],
   "source": [
    "# this takes about 30 seconds per epoch\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(50, slice(1e-2/(2.6**4),1e-2))\n",
    "# after this: learn.fit_one_cycle(10, slice(1e-3/(2.6**4),1e-3))\n",
    "# starts at 0.33 and got to 0.26 - accuracy is decreasing with training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oQWuzoaKvyuc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835
    },
    "id": "oQWuzoaKvyuc",
    "outputId": "b91c38c2-f754-4356-9446-445b9b73e8c0"
   },
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sDunqwzV0WZZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "sDunqwzV0WZZ",
    "outputId": "683f3ac6-d7e5-4d22-da75-8b89fb6b607e"
   },
   "outputs": [],
   "source": [
    "interp = Interpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5Z87Eefu1CA-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "5Z87Eefu1CA-",
    "outputId": "0103ef46-8399-4318-961a-a2384bb84519"
   },
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9, figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oQe44V-M1ECB",
   "metadata": {
    "id": "oQe44V-M1ECB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "text_classification_colab.ipynb",
   "provenance": []
  },
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.3",
    "jupytext_version": "1.11.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
