{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28324895",
   "metadata": {},
   "source": [
    "# Example of how to use Deep Learning for text classification\n",
    "\n",
    "Click [Text Classification Example](https://colab.research.google.com/github/magic-lantern/coprh-nlp-2021/blob/main/text_classification_colab.ipynb) to open this notebook in Google Colab - no local setup required, results saved to your Google Drive.\n",
    "\n",
    "\n",
    "In Google Colab, make sure you change the Runtime to a GPU instance - that will result vastly improved runtimes for deep learning steps. On CPU based hardware some steps take 40 minutes versus 1 minute per training epoch on systems with a GPU. Steps to update runtime:\n",
    "\n",
    "    Runtime > Change runtime type > Select 'GPU' in Hardware accelerator box\n",
    "\n",
    "Click 'Save' to switch from Default runtime to GPU accelerated runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5h_ZvnAlt1QT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5h_ZvnAlt1QT",
    "outputId": "64062d70-d436-4e1f-c6ab-e5053ae5794c"
   },
   "outputs": [],
   "source": [
    "# this cell makes sure Google Colab version has latest software dependencies\n",
    "!pip install -Uqq fastbook fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7SYsu9p6t4b8",
   "metadata": {
    "id": "7SYsu9p6t4b8"
   },
   "outputs": [],
   "source": [
    "import fastbook\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xu500CHUujmu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xu500CHUujmu",
    "outputId": "b884ffb2-4cf8-414e-e1a3-1658ca84ba9a"
   },
   "outputs": [],
   "source": [
    "# this cell will setup a path that allows you to load and save files to your google drive\n",
    "# you will be prompted to log in with a Google enabled account.\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4368554",
   "metadata": {
    "id": "f4368554"
   },
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e8126",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "721e8126",
    "outputId": "57ffb025-0fb7-4e50-c46d-de323b960d79"
   },
   "outputs": [],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61926a1",
   "metadata": {
    "id": "d61926a1"
   },
   "outputs": [],
   "source": [
    "data_path = fastbook.gdrive / Path('data')\n",
    "data_file = data_path / 'mtsamples.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed449f-5443-4a77-947a-e667e021ef24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1ed449f-5443-4a77-947a-e667e021ef24",
    "outputId": "cbc86858-62ca-48fd-b182-ffc2419bd37d"
   },
   "outputs": [],
   "source": [
    "data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e6f504-109b-49ad-a1cb-c08e8352464b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36e6f504-109b-49ad-a1cb-c08e8352464b",
    "outputId": "109f133b-ff0e-464a-812f-3e333d58c6a4"
   },
   "outputs": [],
   "source": [
    "if data_file.is_file():\n",
    "    print('Already downloaded')\n",
    "else:\n",
    "    print('downloading data file')\n",
    "    download_data(\n",
    "        url='https://github.com/socd06/medical-nlp/raw/master/data/mtsamples.csv',\n",
    "        fname = data_file\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52bdf3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "0b52bdf3",
    "outputId": "537766a1-bfd3-47d0-9e66-fa6d07a2ca63"
   },
   "outputs": [],
   "source": [
    "mtsamples = pd.read_csv(str(data_path) + '/mtsamples.csv')\n",
    "mtsamples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fnBYmGT0Nfhn",
   "metadata": {
    "id": "fnBYmGT0Nfhn"
   },
   "outputs": [],
   "source": [
    "# find rows where number of words is very low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e900009",
   "metadata": {
    "id": "8e900009"
   },
   "outputs": [],
   "source": [
    "word_len = mtsamples.transcription.str.split(' ').str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cg1krRikHIZp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cg1krRikHIZp",
    "outputId": "c943c0ff-8214-4625-e1b7-578e474f5af6"
   },
   "outputs": [],
   "source": [
    "word_len.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57axrE6G2W_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a57axrE6G2W_",
    "outputId": "34fdeee5-fa49-4d55-dbbc-93ede132047b"
   },
   "outputs": [],
   "source": [
    "word_len.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9EhzFi6hHDOH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9EhzFi6hHDOH",
    "outputId": "06adf916-af90-4b99-92de-c951ab935c1e"
   },
   "outputs": [],
   "source": [
    "word_len.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a8619",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e35a8619",
    "outputId": "ead46cbb-86ce-4dd9-de91-c828f8d3b7c3"
   },
   "outputs": [],
   "source": [
    "mtsamples.medical_specialty.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a9df06",
   "metadata": {
    "id": "f6a9df06"
   },
   "source": [
    "This is one way to load the data for training\n",
    "\n",
    "```python\n",
    "TextDataLoaders.from_df(mtsamples,\n",
    "                        valid_pct=0.2,\n",
    "                        seed=42,\n",
    "                        text_col='transcription',\n",
    "                        label_col='medical_specialty',\n",
    "                        seq_len=72)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bff6a4",
   "metadata": {
    "id": "65bff6a4"
   },
   "outputs": [],
   "source": [
    "# dls_lm = DataBlock(\n",
    "#     blocks=(TextBlock.from_df('transcription', is_lm=True), CategoryBlock),\n",
    "#     get_x=ColReader('transcription'), \n",
    "#     get_y=ColReader('medical_specialty'),\n",
    "#     splitter=TrainTestSplitter(test_size=0.2,\n",
    "#                                random_state=42,\n",
    "#                                stratify=mtsamples.medical_specialty)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe7270d",
   "metadata": {
    "id": "dfe7270d"
   },
   "outputs": [],
   "source": [
    "dls_lm = DataBlock(\n",
    "    blocks=TextBlock.from_df('transcription', is_lm=True),\n",
    "    get_x=ColReader('text'),\n",
    "    splitter=TrainTestSplitter(test_size=0.2,\n",
    "                               random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FR-C9y-ONUEt",
   "metadata": {
    "id": "FR-C9y-ONUEt"
   },
   "outputs": [],
   "source": [
    "# if changes in the above were made (such as batch size), it may be beneficial to purge GPU memory\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f48b66",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "f5f48b66",
    "outputId": "9e0e1640-f3c9-4421-f883-bcac31cf9a2e"
   },
   "outputs": [],
   "source": [
    "# This cell takes 1 - 2 minutes\n",
    "# when using seq_len, bs of 128 fits in GPU memory, bs 256 does not fit\n",
    "dls_lm = dls_lm.dataloaders(mtsamples, bs=128, seq_len=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a241960c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "a241960c",
    "outputId": "9039a10a-1154-45cf-ab09-ae476de08feb"
   },
   "outputs": [],
   "source": [
    "dls_lm.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a555a56f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "a555a56f",
    "outputId": "e0436c66-1c3a-4e6a-8243-7208e3d00b51"
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(\n",
    "    dls_lm,\n",
    "    AWD_LSTM,\n",
    "    model_dir=fastbook.gdrive / Path('data'),\n",
    "    drop_mult=0.3,\n",
    "    metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c133a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "2e3c133a",
    "outputId": "f82721d3-3150-4c67-d621-d690b4e781da"
   },
   "outputs": [],
   "source": [
    "# on macbook this takes 40 minues\n",
    "# on GPU machine this takes about 1 minute\n",
    "learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8554c3",
   "metadata": {
    "id": "6f8554c3"
   },
   "outputs": [],
   "source": [
    "learn.save('1stepoch')\n",
    "# can load already saved trained model with\n",
    "# learn.load('1stepoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Iu1L2iOOMlxL",
   "metadata": {
    "id": "Iu1L2iOOMlxL"
   },
   "outputs": [],
   "source": [
    "# if changes in the above were made (such as batch size), it may be beneficial to purge GPU memory\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6wi48g8_3aEM",
   "metadata": {
    "id": "6wi48g8_3aEM"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, 2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wshP_Vru55lX",
   "metadata": {
    "id": "wshP_Vru55lX"
   },
   "outputs": [],
   "source": [
    "learn.save_encoder('finetuned')\n",
    "# can load with\n",
    "# learn.load('finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9QlB-_EK-61",
   "metadata": {
    "id": "e9QlB-_EK-61"
   },
   "outputs": [],
   "source": [
    "learn.load('somef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hnNH9BtsK0rT",
   "metadata": {
    "id": "hnNH9BtsK0rT"
   },
   "outputs": [],
   "source": [
    "if (Path('/content/gdrive/My Drive/data/finetuned.pth').is_file()):\n",
    "  print('Loading previously saved language model learner')\n",
    "  learn.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H7r0efIX5_YS",
   "metadata": {
    "id": "H7r0efIX5_YS"
   },
   "outputs": [],
   "source": [
    "dls_lm = DataBlock(\n",
    "    blocks=TextBlock.from_df('transcription', is_lm=True),\n",
    "    get_x=ColReader('text'),\n",
    "    #get_y='medical_specialty',\n",
    "    splitter=TrainTestSplitter(test_size=0.2,\n",
    "                               random_state=42,\n",
    "                               stratify=mtsamples.medical_specialty)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "S63CGt8l5_y4",
   "metadata": {
    "id": "S63CGt8l5_y4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yLNdc8BW5__H",
   "metadata": {
    "id": "yLNdc8BW5__H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "text_classification_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
